#' Reg_parCI
#'
#' @name Reg_parCI
#' @param add_data
#' A numeric matrix of air temperature data as that calculated by the dataset_add().
#' @param model
#' A single interger number from 1 to 4 defining the GEV model.
#' May be provided by best_model()
#' @param reg_par
#' A 5-column and 1-row data.frame or matrix as that generated by reg_par().
#'  * 1st column is the mu0 parameter,
#'  * 2nd is the mu1 parameter,
#'  * 3rd is the sigma0 parameter,
#'  * 4th is the sigma1 parameter,
#'  * 5th is the shape parameter
#' @param n.boots
#' A single number describing the number of copies of the original dataset.
#' Whenever possible n.boots should be set to 999 (its default value),
#' as suggested by Burn (2003) <10.1623/hysj.48.1.25.43485> and
#' Oâ€™Brien and Burn (2014) <10.1016/j.jhydrol.2014.09.041>.
#' @return
#' A matrix containing the 95% confidence intervals (lower and upper bounds)
#' of the time-varying parameter estimates. The spatial dependence between sites is preserved.
#' @export
#' @importFrom stats quantile
#' @examplesIf interactive()
#' add_data <- add_data
#' model <- 2
#' reg_par <- regional_pars
#' n.boots <- 100
#' Reg_parCI(add_data, model, reg_par, n.boots)
Reg_parCI <- function(add_data,model,reg_par,n.boots){
  if (is.null(n.boots)) {
    n.boots <- 999
  }
  if (n.boots < 100) {stop("n.boots must be larger than 99 and, if possible, equal to 999.")}
  n.sites <- ncol(add_data)
  if (n.sites < 7) {
    stop("The number of sites should be larger than 6.")
  }
  min_sample_size <- min(colSums(!is.na(add_data)))

  if (min_sample_size < 10) {
    stop("All sites must have at least 10 years of records. So sorry, we cannot proceed.")
  }
  reg_par <- as.matrix(reg_par)
  # Check that reg_par is numeric
  if (!all(sapply(reg_par, is.numeric))) {
    stop("Input 'reg_par' must be a numeric data frame or matrix with 5 columns.")
  }
  if (ncol(reg_par) != 5 || nrow(reg_par) != 1) {
    stop("Input 'reg_par' must have exactly 1 row and 5 columns.")
  }
  reg_par <- as.numeric(reg_par)
  max_time <- nrow(add_data)
  par.temporal <- matrix(NA,max_time,3)
  scaled <- scale(1L:max_time)
  time <- scaled[,1]
  IDD.series <- add_data
  for (site in 1:n.sites){
    par.temporal[,1] <- reg_par[1] + reg_par[2] * time
    par.temporal[,2] <- reg_par[3] + reg_par[4] * time
    par.temporal[,3] <-  rep(reg_par[5],max_time)
    IDD.series[,site] <- (1- par.temporal[,3]*(add_data[,site]-par.temporal[,1])/par.temporal[,2])^(1/par.temporal[,3])
  }
  ##################
  all.lines <- n.boots * max_time
  resample.vector <- seq_len(max_time)

  # Preallocate matrix
  IDD.series.boot <- matrix(NA_real_, all.lines, n.sites)

  # Vectorized resampling
  resampled_indices <- replicate(n.boots, sample(resample.vector, replace = TRUE))
  IDD.series.boot <- IDD.series[as.vector(resampled_indices), , drop = FALSE]

  # Shuffle rows
  IDD.series.boot <- IDD.series.boot[sample(seq_len(all.lines)), , drop = FALSE]

  # Preallocate matrices
  reg_par.overall.boot <- matrix(NA_real_, n.boots, 5)
  message("This calculation takes a real while.")
  pb <- txtProgressBar(min = 0, max = n.boots, style = 3)
  for (r in seq_len(n.boots)) {
    rows <- ((r - 1) * max_time + 1):(r * max_time)
    back.orig <- par.temporal[,1] + (par.temporal[,2] / par.temporal[,3]) * (1 - IDD.series.boot[rows, ]^par.temporal[,3])
    find.best.boot <- fit_model(temperatures=back.orig,model=model)
    reg_par.overall.boot[r, ] <- as.matrix(reg_par(best_model=find.best.boot))
    setTxtProgressBar(pb, r)
  }
  close(pb)
  # Compute the 95% confidence intervals (row-wise quantiles)
  CI_lower <- apply(reg_par.overall.boot, 2, quantile, probs = 0.025, na.rm = TRUE)
  CI_upper <- apply(reg_par.overall.boot, 2, quantile, probs = 0.975, na.rm = TRUE)

  # Combine into a matrix for easy visualization
  CI_matrix <- rbind(CI_lower, CI_upper)
  rownames(CI_matrix) <- c("Lower 95% CI", "Upper 95% CI")
  colnames(CI_matrix) <- c("weighted_mu0", "weighted_mu1", "weighted_sigma0", "weighted_sigma1", "weighted_shape")
  # Print results
  return(CI_matrix)
}
